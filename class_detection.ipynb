{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# Import PyTorch modules (edit this list if needed)\n",
    "import torch\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from matplotlib import image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/maxence/enseirb-s9-doodle-computer-vision/classDetection.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/classDetection.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/classDetection.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/classDetection.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH, HEIGHT = 26, 26\n",
    "EPOCHS = 20\n",
    "classes = []\n",
    "nb_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dir: str, width: int=128, height: int=128):\n",
    "        super().__init__()\n",
    "\n",
    "        assert width==height\n",
    "        self.size = (width, height)\n",
    "\n",
    "        self._get_data(dir)\n",
    "        self.data = [self._convert_img_to_np_arrays(path) for path in self.data_paths]\n",
    "        \n",
    "        \n",
    "    def _get_data(self, dir):\n",
    "        self.data_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for sub_dir, label in zip(os.listdir(dir), [0,1]):\n",
    "            self.data_paths += [dir+\"/\"+sub_dir+\"/\"+img for img in os.listdir(dir+\"/\"+sub_dir)]\n",
    "            self.labels += [label]*len(os.listdir(dir+\"/\"+sub_dir))\n",
    "        self.data_paths=np.array(self.data_paths)\n",
    "        self.labels=np.array(self.labels)\n",
    "\n",
    "    def _convert_img_to_np_arrays(self, img_path):\n",
    "        from PIL import Image\n",
    "\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        # we resize images so they all have the same shape\n",
    "        resized_image = image.resize(self.size)\n",
    "\n",
    "        # we normalize images so all values are between 0 and 1\n",
    "        np_image = np.array(resized_image, dtype=float)/255.0\n",
    "\n",
    "        np_image = np_image.astype(np.float32)\n",
    "\n",
    "        # we transpose the matrix so it follows \"channel first\" convention\n",
    "        np_image = np.transpose(np_image, (2, 0, 1))\n",
    "\n",
    "        return np_image\n",
    "\n",
    "    def __getitem__(self, key: int):\n",
    "        assert key < self.__len__()\n",
    "\n",
    "        img = self.data[key]\n",
    "        label = self.labels[key]\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_set = CustomDataset(\"\")\n",
    "validation_set = CustomDataset(\"\")\n",
    "\n",
    "#################################################################\n",
    "\n",
    "batch_size: int = 32\n",
    "\n",
    "training_loaded_set = DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "validation_loaded_set = DataLoader(validation_set, batch_size=batch_size , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_and_accuracy_per_epoch(model):\n",
    "    plt.plot(model.nb_epochs, model.loss_history)\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('loss per epoch')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(model.nb_epochs, model.train_acc_history, label='training')\n",
    "    plt.plot(model.nb_epochs, model.valid_acc_history, label='validation')\n",
    "    plt.ylabel('accuracy in %')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.title('accuracy per epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, width: int, height: int):\n",
    "        super().__init__()\n",
    "\n",
    "        filter_size: int = 5\n",
    "        self.conv1 = nn.Conv2d(3, 6, filter_size)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, filter_size)\n",
    "\n",
    "        shape_after_conv = int((((width-4)/2)-4)/2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * shape_after_conv * shape_after_conv, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        input = self.forward(x)\n",
    "        m = nn.Softmax(dim=1)\n",
    "        return m(input)\n",
    "\n",
    "\n",
    "\n",
    "model = Net(128, 128)\n",
    "print(model)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "print(f'number of trainable parameters : {sum([np.prod(p.size()) for p in model_parameters])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPUNet(Net):\n",
    "    def __init__(self, width: int, height: int, device):\n",
    "        super().__init__(width, height)\n",
    "        self._device = device\n",
    "\n",
    "    def fit(self, train_loader, valid_loader, nb_epochs:int =10):\n",
    "        self.loss_history = []\n",
    "        self.train_acc_history = []\n",
    "        self.valid_acc_history = []\n",
    "\n",
    "        self.nb_epochs = [epoch+1 for epoch in range(nb_epochs)]\n",
    "\n",
    "        import torch.optim as optim\n",
    "        \n",
    "        optimizer = optim.SGD(self.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        for epoch in self.nb_epochs:\n",
    "\n",
    "            running_loss = 0.0\n",
    "            nb_batch = 0\n",
    "\n",
    "            for i, data in enumerate(train_loader, start=0):\n",
    "                nb_batch+=1\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(self._device), labels.to(self._device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = self.forward(inputs)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "            running_loss/=nb_batch\n",
    "            train_acc = self.compute_accuracy(train_loader)*100\n",
    "            valid_acc = self.compute_accuracy(valid_loader)*100\n",
    "            \n",
    "            print(f'epoch [{epoch}/{len(self.nb_epochs)}], loss : {running_loss}, train acc : {round(train_acc,3)}%, valid acc : {round(valid_acc,3)}%')\n",
    "            self.loss_history.append(running_loss)\n",
    "            self.train_acc_history.append(train_acc)\n",
    "            self.valid_acc_history.append(valid_acc)\n",
    "                    \n",
    "        print('Finished Training')\n",
    "\n",
    "        end_time = time.time()\n",
    "        self.training_time = end_time - start_time\n",
    "\n",
    "    def compute_accuracy(self, dataset: DataLoader):\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        for data in dataset:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(self._device), labels.to(self._device)\n",
    "\n",
    "            outputs = self.predict(inputs)\n",
    "            _, predicted_classes = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted_classes == labels).sum().item()\n",
    "\n",
    "        return correct/total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VGG16FeatureExtractor(GPUNet):\n",
    "    def __init__(self, width: int, height: int, device):\n",
    "        super(VGG16FeatureExtractor, self).__init__(width, height, device)\n",
    "\n",
    "        vgg16 = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "\n",
    "        # set vgg16 layers to not trainable\n",
    "        for param in vgg16.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.features = vgg16.features\n",
    "        self.avgpool = vgg16.avgpool\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(500, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def fit(self, train_loader, valid_loader, nb_epochs:int =10):\n",
    "        self.loss_history = []\n",
    "        self.train_acc_history = []\n",
    "        self.valid_acc_history = []\n",
    "        \n",
    "        self.nb_epochs = [epoch+1 for epoch in range(nb_epochs)]\n",
    "\n",
    "        import torch.optim as optim\n",
    "        \n",
    "        optimizer = optim.SGD(self.classifier.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        for epoch in self.nb_epochs:\n",
    "\n",
    "            running_loss = 0.0\n",
    "            nb_batch = 0\n",
    "\n",
    "            for i, data in enumerate(train_loader, start=0):\n",
    "                nb_batch+=1\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(self._device), labels.to(self._device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = self.forward(inputs)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "            running_loss/=nb_batch\n",
    "            train_acc = self.compute_accuracy(train_loader)*100\n",
    "            valid_acc = self.compute_accuracy(valid_loader)*100\n",
    "            \n",
    "            print(f'epoch [{epoch}/{len(self.nb_epochs)}], loss : {running_loss}, train acc : {round(train_acc,3)}%, valid acc : {round(valid_acc,3)}%')\n",
    "            self.loss_history.append(running_loss)\n",
    "            self.train_acc_history.append(train_acc)\n",
    "            self.valid_acc_history.append(valid_acc)\n",
    "                    \n",
    "        print('Finished Training')\n",
    "\n",
    "        end_time = time.time()\n",
    "        self.training_time = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VGG16FeatureExtractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/maxence/enseirb-s9-doodle-computer-vision/classDetection.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/classDetection.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m vgg16_model \u001b[39m=\u001b[39m VGG16FeatureExtractor(WIDTH, HEIGHT, device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/classDetection.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m total_params \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mnumel() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m vgg16_model\u001b[39m.\u001b[39mparameters())\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/classDetection.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTotal number of parameters: \u001b[39m\u001b[39m{\u001b[39;00mtotal_params\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VGG16FeatureExtractor' is not defined"
     ]
    }
   ],
   "source": [
    "vgg16_model = VGG16FeatureExtractor(WIDTH, HEIGHT, device)\n",
    "\n",
    "total_params = sum(p.numel() for p in vgg16_model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n",
    "\n",
    "vgg16_model.to(device)\n",
    "vgg16_model.fit(augmented_training_loaded_set, validation_loaded_set, nb_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_and_accuracy_per_epoch(vgg16_model)\n",
    "\n",
    "print(f'training accuracy : {vgg16_model.compute_accuracy(training_loaded_set)*100} %')\n",
    "print(f'validaiton accuracy : {vgg16_model.compute_accuracy(validation_loaded_set)*100} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
