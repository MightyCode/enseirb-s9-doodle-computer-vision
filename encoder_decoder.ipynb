{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "# Import PyTorch modules (edit this list if needed)\n",
    "import torch\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from matplotlib import image as mpimg\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH, HEIGHT = 28, 28\n",
    "EPOCHS: int = 20\n",
    "BATCH_SIZE: int = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources_folder = 'resources/classification'\n",
    "\n",
    "classes = ['apple', 'golf club', 'hedgehog', 'moon', 'mushroom', 'rain', 'roller coaster', 'squirrel']\n",
    "nb_classes = len(classes)\n",
    "\n",
    "data = [np.load(os.path.join(resources_folder, 'full_numpy_bitmap_'+class_name+'.npy')) for class_name in classes]\n",
    "print(f'loaded numpy bitmaps, {nb_classes} classes')\n",
    "\n",
    "print(len(data))\n",
    "print(data[0].shape)\n",
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = []\n",
    "\n",
    "for class_data in data:\n",
    "    array = random.choice(class_data).reshape(WIDTH, HEIGHT)\n",
    "    to_plot.append(array)\n",
    "\n",
    "num_cols = 4\n",
    "num_rows = 2\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 6))\n",
    "\n",
    "for i in range(nb_classes):\n",
    "    row_index = i // num_cols\n",
    "    col_index = i % num_cols\n",
    "    axes[row_index, col_index].imshow(to_plot[i], cmap='gray')\n",
    "    axes[row_index, col_index].axis('off')\n",
    "    axes[row_index, col_index].set_title(classes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Random element from each class')\n",
    "\n",
    "plt.subplots_adjust(top=0.9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_creation.DataManager import DataManager\n",
    "\n",
    "split = 0.8\n",
    "data_manager = DataManager()\n",
    "\n",
    "training_data, training_labels, validation_data, validation_labels = data_manager.split_data(split, data)\n",
    "\n",
    "print(f'training dataset size : {len(training_data)}')\n",
    "print(f'validation dataset size : {len(validation_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_training_data, shuffled_training_labels = data_manager.shuffle_dataset(training_data, training_labels)\n",
    "\n",
    "shuffled_validation_data, shuffled_validation_labels = data_manager.shuffle_dataset(validation_data, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_creation.GraysacleDataset import GrayscaleDataset\n",
    "\n",
    "len_subset = 2000\n",
    "\n",
    "training_set = GrayscaleDataset(data=shuffled_training_data[:len_subset], labels=shuffled_training_labels[:len_subset],\n",
    "                             width=WIDTH, height=HEIGHT, reshape=False, normalize=True)\n",
    "validation_set = GrayscaleDataset(data=shuffled_validation_data[:len_subset], labels=shuffled_validation_labels[:len_subset],\n",
    "                             width=WIDTH, height=HEIGHT, reshape=False, normalize=True)\n",
    "\n",
    "training_loaded_set = DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loaded_set = DataLoader(validation_set, batch_size=BATCH_SIZE , shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.autoencoder import Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_1 = [WIDTH * HEIGHT, WIDTH * HEIGHT // 2, WIDTH * HEIGHT // 4]\n",
    "autoencoder_model = Autoencoder(architecture_1, device, WIDTH, HEIGHT, classes)\n",
    "autoencoder_model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print architecture \n",
    "autoencoder_model.print_model()\n",
    "\n",
    "# Compression factor \n",
    "print(f'Compression factor: {WIDTH * HEIGHT / architecture_1[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "autoencoder_model.train_autoencoder(training_loaded_set, validation_loaded_set, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Train and Test Loss, PSNR and SSIM values\n",
    "autoencoder_model.plot_psnr_ssim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some original and reconstructed images\n",
    "autoencoder_model.show_images(training_set, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_BACTH_SIZE = 8000\n",
    "\n",
    "training_check_dataloader= DataLoader(training_set, batch_size=CHECK_BACTH_SIZE, shuffle=False)\n",
    "validation_check_dataloader = DataLoader(validation_set, batch_size=CHECK_BACTH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the lowest psnr then ssim in the test set\n",
    "lowest_psnr, lowest_ssim = autoencoder_model.return_lowest_image_index_psnr_ssim(validation_check_dataloader)\n",
    "print(f'Lowest PSNR index: {lowest_psnr[0]} | {lowest_psnr[1]}, Lowest SSIM index: {lowest_ssim[0]} | {lowest_ssim[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image with the lowest psnr and ssim compared to their original the test set on same plot\n",
    "print(lowest_psnr)\n",
    "print(lowest_ssim)\n",
    "autoencoder_model.show_lowest_psnr_ssim_image(validation_set, lowest_psnr, lowest_ssim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with a different model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [WIDTH * HEIGHT, WIDTH * HEIGHT]\n",
    "autocoder_2 = Autoencoder(layers, device, WIDTH, HEIGHT, classes)\n",
    "autocoder_2.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autocoder_2.parameters(), lr=0.001)\n",
    "\n",
    "# Print architecture\n",
    "autocoder_2.print_model()\n",
    "\n",
    "# Compression factor\n",
    "print(f'Compression factor: {WIDTH * HEIGHT / autocoder_2.architecture[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "num_epochs = 40\n",
    "\n",
    "autocoder_2.train_autoencoder(training_loaded_set, validation_loaded_set, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocoder_2.plot_psnr_ssim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocoder_2.show_images(training_set, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_psnr, lowest_ssim = autocoder_2.return_lowest_image_index_psnr_ssim(validation_check_dataloader)\n",
    "print(f'Lowest PSNR index: {lowest_psnr[0]}|{lowest_psnr[1]}, Lowest SSIM index: {lowest_ssim[0]}|{lowest_ssim[1]}')\n",
    "\n",
    "autocoder_2.show_lowest_psnr_ssim_image(validation_set, lowest_psnr, lowest_ssim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with resnet18 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pretrained model\n",
    "\n",
    "# Load pretrained model\n",
    "\n",
    "pretrained_model = models.resnet18(pretrained=True)\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "# Print pretrained model architecture\n",
    "print(pretrained_model)\n",
    "\n",
    "# Freeze all layers\n",
    "\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Add custom layers\n",
    "\n",
    "pretrained_model.fc = nn.Sequential(\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, nb_classes)\n",
    ")\n",
    "\n",
    "# Print new model architecture\n",
    "print(pretrained_model)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(pretrained_model.fc.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train the model\n",
    "def train_pretained_model():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_classes_mean_encoded_vector(model, images_set):\n",
    "    mean_encoded_vectors = []\n",
    "    mean_vectors_size = model.architecture[-1]\n",
    "    count_classes_number = [0] * nb_classes\n",
    "\n",
    "    for i in range(nb_classes):\n",
    "        mean_encoded_vectors.append(np.zeros(mean_vectors_size))\n",
    "\n",
    "    for batch in images_set:\n",
    "        images, labels = batch\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        encoded, decoded = model(images)\n",
    "        encoded_np = encoded.cpu().detach().numpy()\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            mean_encoded_vectors[labels[i]] += encoded_np[i]\n",
    "\n",
    "        count_classes_number[labels[i]] += 1\n",
    "            \n",
    "    for i in range(nb_classes):\n",
    "        mean_encoded_vectors[i] = mean_encoded_vectors[i] / count_classes_number[i] / 255.0\n",
    "\n",
    "        print(f'Class {classes[i]} range of mean encoded vector: [{mean_encoded_vectors[i].min()}, {mean_encoded_vectors[i].max()}]')\n",
    "\n",
    "    return mean_encoded_vectors\n",
    "\n",
    "def generated_images_for_mean_vector(mean_encoded_vectors, model):\n",
    "    generated_images = []\n",
    "\n",
    "    decoder = model.decoder\n",
    "    for i in range(nb_classes):\n",
    "        mean_vector = mean_encoded_vectors[i]\n",
    "        double_mean_vector = np.array([mean_vector]).astype(np.float32)\n",
    "        mean_vector_torch = torch.from_numpy(double_mean_vector).to(device)\n",
    "\n",
    "        decoded = decoder(mean_vector_torch)\n",
    "\n",
    "        generated_images.append(decoded.cpu().detach().numpy()[0].reshape(HEIGHT, WIDTH))\n",
    "\n",
    "    return generated_images\n",
    "\n",
    "def show_generated_images(generated_images):\n",
    "    num_cols = 4\n",
    "    num_rows = 2\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 6))\n",
    "\n",
    "    for i in range(nb_classes):\n",
    "        row_index = i // num_cols\n",
    "        col_index = i % num_cols\n",
    "        axes[row_index, col_index].imshow(generated_images[i], cmap='gray')\n",
    "        axes[row_index, col_index].axis('off')\n",
    "        axes[row_index, col_index].set_title(classes[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Generated images')\n",
    "\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_alternative_version(mean_vector, weight=0.1):\n",
    "    alternative_mean_vector = mean_vector.copy()\n",
    "    # Vector is composed of float values \n",
    "    # use gaussian distribution to generate altertivate vector based on mean one\n",
    "\n",
    "    for i in range(len(mean_vector)):\n",
    "        alternative_mean_vector[i] = np.random.normal(mean_vector[i], weight)\n",
    "    \n",
    "    return alternative_mean_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_encoded_vectors = return_classes_mean_encoded_vector(autoencoder_model, training_loaded_set)\n",
    "generated_images = generated_images_for_mean_vector(mean_encoded_vectors, autoencoder_model)\n",
    "show_generated_images(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_versions = []\n",
    "for mean_encoded_vector in mean_encoded_vectors:\n",
    "    alternative_versions.append(create_alternative_version(mean_encoded_vector, 0.05))\n",
    "\n",
    "alternative_generated_version = generated_images_for_mean_vector(alternative_versions, autoencoder_model)\n",
    "show_generated_images(alternative_generated_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_encoded_vectors = return_classes_mean_encoded_vector(autoencoder_model, training_loaded_set)\n",
    "generated_images = generated_images_for_mean_vector(mean_encoded_vectors, autoencoder_model)\n",
    "show_generated_images(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_versions = []\n",
    "for mean_encoded_vector in mean_encoded_vectors:\n",
    "    alternative_versions.append(create_alternative_version(mean_encoded_vector, 0.05))\n",
    "\n",
    "alternative_generated_version = generated_images_for_mean_vector(alternative_versions, autoencoder_model)\n",
    "show_generated_images(alternative_generated_version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
