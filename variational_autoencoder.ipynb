{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Auto\\-Encodeur Variationnel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0+cu121\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "# Import PyTorch modules (edit this list if needed)\n",
    "import torch\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from matplotlib import image as mpimg\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "WIDTH, HEIGHT = 28, 28\n",
    "EPOCHS: int = 20\n",
    "BATCH_SIZE: int = 32\n",
    "latent_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded numpy bitmaps, 8 classes\n"
     ]
    }
   ],
   "source": [
    "resources_folder = 'resources/classification'\n",
    "\n",
    "classes = ['apple', 'golf club', 'hedgehog', 'moon', 'mushroom', 'rain', 'roller coaster', 'squirrel']\n",
    "nb_classes = len(classes)\n",
    "\n",
    "data = [np.load(os.path.join(resources_folder, 'full_numpy_bitmap_'+class_name+'.npy')) for class_name in classes]\n",
    "print(f'loaded numpy bitmaps, {nb_classes} classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_plot = []\n",
    "\n",
    "for class_data in data:\n",
    "    array = random.choice(class_data).reshape(WIDTH, HEIGHT)\n",
    "    to_plot.append(array)\n",
    "\n",
    "num_cols = 4\n",
    "num_rows = 2\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 6))\n",
    "\n",
    "for i in range(nb_classes):\n",
    "    row_index = i // num_cols\n",
    "    col_index = i % num_cols\n",
    "    axes[row_index, col_index].imshow(to_plot[i], cmap='gray')\n",
    "    axes[row_index, col_index].axis('off')\n",
    "    axes[row_index, col_index].set_title(classes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Random element from each class')\n",
    "\n",
    "plt.subplots_adjust(top=0.9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset size : 927239\n",
      "validation dataset size : 231814\n"
     ]
    }
   ],
   "source": [
    "from dataset_creation.DataManager import DataManager\n",
    "\n",
    "split = 0.8\n",
    "data_manager = DataManager()\n",
    "\n",
    "training_data, training_labels, validation_data, validation_labels = data_manager.split_data(split, data)\n",
    "\n",
    "print(f'training dataset size : {len(training_data)}')\n",
    "print(f'validation dataset size : {len(validation_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "shuffled_training_data, shuffled_training_labels = data_manager.shuffle_dataset(training_data, training_labels)\n",
    "\n",
    "shuffled_validation_data, shuffled_validation_labels = data_manager.shuffle_dataset(validation_data, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from dataset_creation.GraysacleDataset import GrayscaleDataset\n",
    "\n",
    "len_subset = 2000\n",
    "\n",
    "training_set = GrayscaleDataset(data=shuffled_training_data[:len_subset], labels=shuffled_training_labels[:len_subset],\n",
    "                             width=WIDTH, height=HEIGHT, reshape=False, normalize=True)\n",
    "validation_set = GrayscaleDataset(data=shuffled_validation_data[:len_subset], labels=shuffled_validation_labels[:len_subset],\n",
    "                             width=WIDTH, height=HEIGHT, reshape=False, normalize=True)\n",
    "\n",
    "training_loaded_set = DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loaded_set = DataLoader(validation_set, batch_size=BATCH_SIZE , shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Variationel Autoencoder class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class VarAutoencoder(nn.Module):\n",
    "    def __init__(self, layer_sizes=[(WIDTH * HEIGHT), 128, 64, 32]):\n",
    "        super(VarAutoencoder, self).__init__()\n",
    "        self.architecture = layer_sizes\n",
    "        self.encoder = nn.Sequential()\n",
    "        self.decoder = nn.Sequential()\n",
    "\n",
    "        # Add encoder layers\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            self.encoder.add_module(f\"encoder_{i}\", nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
    "            if i < len(layer_sizes) - 2:\n",
    "                self.encoder.add_module(f\"encoder_relu_{i}\", nn.ReLU())\n",
    "                self.encoder.add_module(f\"encoder_dropout_{i}\", nn.Dropout(0.3))\n",
    "                self.encoder.add_module(f\"encoder_batchnorm_{i}\", nn.BatchNorm1d(layer_sizes[i+1]))\n",
    "\n",
    "        self.mu = nn.Linear(layer_sizes[-1], latent_dim)\n",
    "        self.logvar = nn.Linear(layer_sizes[-1], latent_dim)\n",
    "\n",
    "        # Add decoder layers\n",
    "        for i in range(len(layer_sizes) - 1, 0, -1):\n",
    "            self.decoder.add_module(f\"decoder_{i}\", nn.Linear(layer_sizes[i], layer_sizes[i-1]))\n",
    "            if i > 1:\n",
    "                self.decoder.add_module(f\"decoder_relu_{i}\", nn.ReLU())\n",
    "                self.decoder.add_module(f\"encoder_dropout_{i}\", nn.Dropout(0.3))\n",
    "                self.decoder.add_module(f\"encoder_batchnorm_{i}\", nn.BatchNorm1d(layer_sizes[i+1]))\n",
    "\n",
    "        self.decoder.add_module(\"decoder_sigmoid\", nn.Sigmoid())\n",
    "\n",
    "    def sampling(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, WIDTH * HEIGHT)\n",
    "        encoded = self.encoder(x)\n",
    "        mu = self.mu(encoded)\n",
    "        logvar = self.logvar(encoded)\n",
    "        \n",
    "        z = self.sampling(mu, logvar)\n",
    "        \n",
    "        decoded = self.decoder(z)\n",
    "        \n",
    "        return mu, logvar, decoded\n",
    "\n",
    "    def print_model(self):\n",
    "        print(self.encoder)\n",
    "        print(self.mu)\n",
    "        print(self.logvar)\n",
    "        print(self.decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Try with simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "beta = 1.0\n",
    "\n",
    "def vae_loss(mu, logvar, decoded, inputs):\n",
    "    # Fonction de perte de reconstruction (MSE dans ce cas)\n",
    "    reconstruction_loss = F.mse_loss(decoded, inputs.view(-1, WIDTH * HEIGHT), reduction='sum')\n",
    "\n",
    "    # KL divergence entre la distribution latente et une distribution normale\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    # Combinaison des deux termes de perte\n",
    "    return reconstruction_loss + beta * kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "architecture_1 = [WIDTH * HEIGHT, WIDTH * HEIGHT // 3]\n",
    "autoencoder_model = VarAutoencoder(architecture_1).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = vae_loss\n",
    "optimizer = torch.optim.Adam(autoencoder_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (encoder_0): Linear(in_features=784, out_features=261, bias=True)\n",
      ")\n",
      "Linear(in_features=261, out_features=2, bias=True)\n",
      "Linear(in_features=261, out_features=2, bias=True)\n",
      "Sequential(\n",
      "  (decoder_1): Linear(in_features=261, out_features=784, bias=True)\n",
      "  (decoder_sigmoid): Sigmoid()\n",
      ")\n",
      "Compression factor: 3.003831417624521\n"
     ]
    }
   ],
   "source": [
    "# Print architecture \n",
    "autoencoder_model.print_model()\n",
    "\n",
    "# Compression factor \n",
    "print(f'Compression factor: {WIDTH * HEIGHT / architecture_1[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_autoencoder(autoencoder_model, train_loader: DataLoader, valid_loader: DataLoader, criterion, optimizer, num_epochs):\n",
    "    train_psnr_values = []\n",
    "    train_ssim_values = []\n",
    "\n",
    "    validation_psnr_values = []\n",
    "    validation_ssim_values = []\n",
    "\n",
    "    train_loss_values = []\n",
    "    validation_loss_values = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train by batch of images\n",
    "        for data in train_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            mu, logvar, decoded = autoencoder_model.forward(inputs)\n",
    "            loss = criterion(mu, logvar, decoded, inputs)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Train loss\n",
    "        train_loss_values.append(loss.item())\n",
    "\n",
    "        # loop on validation to compute validation loss\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            \n",
    "            # Forward pass\n",
    "            mu, logvar, decoded = autoencoder_model.forward(inputs)\n",
    "            loss = criterion(mu, logvar, decoded, inputs)\n",
    "\n",
    "        validation_loss_values.append(loss.item())\n",
    "\n",
    "        # Calculate PSNR and SSIM for train and test sets\n",
    "        train_psnr = 0\n",
    "        train_ssim = 0\n",
    "        validation_psnr = 0\n",
    "        validation_ssim = 0\n",
    "\n",
    "        nb_train_images = 0\n",
    "        nb_valid_images = 0\n",
    "        \n",
    "        for data in train_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            for i in range(inputs.size(0)):\n",
    "                nb_train_images+=1\n",
    "                img_as_tensor = inputs[i]\n",
    "\n",
    "                _, _, decoded = autoencoder_model(img_as_tensor)\n",
    "\n",
    "                image_matrix = img_as_tensor.cpu().detach().numpy()\n",
    "                decoded_matrix = decoded.cpu().detach().numpy()\n",
    "\n",
    "                train_psnr += psnr(image_matrix, decoded_matrix)\n",
    "                train_ssim += ssim(image_matrix, decoded_matrix, data_range=decoded_matrix.max() - decoded_matrix.min())\n",
    "\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            for i in range(inputs.size(0)):\n",
    "                nb_valid_images+=1\n",
    "                img_as_tensor = inputs[i]\n",
    "\n",
    "                _, _, decoded = autoencoder_model(img_as_tensor)\n",
    "\n",
    "                image_matrix = img_as_tensor.cpu().detach().numpy()\n",
    "                decoded_matrix = decoded.cpu().detach().numpy()\n",
    "\n",
    "                validation_psnr += psnr(image_matrix, decoded_matrix)\n",
    "                validation_ssim += ssim(image_matrix, decoded_matrix, data_range=decoded_matrix.max() - decoded_matrix.min())\n",
    "\n",
    "        train_psnr /= nb_train_images\n",
    "        train_ssim /= nb_train_images\n",
    "        validation_psnr /= nb_valid_images\n",
    "        validation_ssim /= nb_valid_images\n",
    "\n",
    "        train_psnr_values.append(train_psnr)\n",
    "        train_ssim_values.append(train_ssim)\n",
    "        validation_psnr_values.append(validation_psnr)\n",
    "        validation_ssim_values.append(validation_ssim)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss_values[-1]:.4f}, Test Loss {validation_loss_values[-1]:.4f}, ', end = \"\")\n",
    "        print(f'Train PSNR: {train_psnr:.4f}, Train SSIM: {train_ssim:.4f}, Validation PSNR: {validation_psnr:.4f}, Validation SSIM: {validation_ssim:.4f}')\n",
    "\n",
    "    return train_loss_values, validation_loss_values, train_psnr_values, train_ssim_values, validation_psnr_values, validation_ssim_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x2 and 261x784)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb Cell 19\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Call the function\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m40\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_loss_values, validation_loss_values, train_psnr_values, train_ssim_values, validation_psnr_values, validation_ssim_values \\\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m=\u001b[39m train_autoencoder(autoencoder_model, training_loaded_set, validation_loaded_set, criterion, optimizer, num_epochs)\n",
      "\u001b[1;32m/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m mu, logvar, decoded \u001b[39m=\u001b[39m autoencoder_model\u001b[39m.\u001b[39;49mforward(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb#X24sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(mu, logvar, decoded, inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb#X24sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n",
      "\u001b[1;32m/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb Cell 19\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb#X24sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m logvar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogvar(encoded)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb#X24sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling(mu, logvar)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb#X24sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m decoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(z)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxence/enseirb-s9-doodle-computer-vision/variational_autoencoder.ipynb#X24sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mreturn\u001b[39;00m mu, logvar, decoded\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x2 and 261x784)"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "num_epochs = 40\n",
    "train_loss_values, validation_loss_values, train_psnr_values, train_ssim_values, validation_psnr_values, validation_ssim_values \\\n",
    "    = train_autoencoder(autoencoder_model, training_loaded_set, validation_loaded_set, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to plot Train and Test Loss, PSNR and SSIM values\n",
    "def plot_psnr_ssim(train_loss_values, test_loss_values, train_psnr_values, test_psnr_values, train_ssim_values, test_ssim_values):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 6))\n",
    "\n",
    "    axes[0].plot(train_loss_values, label='Train Loss')\n",
    "    axes[0].plot(test_loss_values, label='Validation Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(train_psnr_values, label='Train PSNR')\n",
    "    axes[1].plot(test_psnr_values, label='Validation PSNR')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('PSNR')\n",
    "    axes[1].legend()\n",
    "\n",
    "    axes[2].plot(train_ssim_values, label='Train SSIM')\n",
    "    axes[2].plot(test_ssim_values, label='Validation SSIM')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('SSIM')\n",
    "    axes[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Call the function\n",
    "plot_psnr_ssim(train_loss_values, validation_loss_values, train_psnr_values, validation_psnr_values, train_ssim_values, validation_ssim_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to show original and reconstructed images\n",
    "def show_images(train_set, validation_set, autoencoder_model):\n",
    "    num_cols = 4\n",
    "    num_rows = 2\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 6))\n",
    "\n",
    "    for i in range(num_cols // 2):\n",
    "        # Train images\n",
    "        index = random.randint(0, train_set.__len__())\n",
    "\n",
    "        axes[0, i].imshow(train_set.get_image_2d(index), cmap='gray')\n",
    "        axes[0, i].set_title(f\"Train original {train_set[index][1]}\")\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "        # Reconstructed images\n",
    "        train_tensor = torch.from_numpy(train_set[index][0]).to(device)\n",
    "        encoded, decoded = autoencoder_model(train_tensor)\n",
    "        decoded = decoded.view(-1, HEIGHT, WIDTH)  # Reshape decoded images\n",
    "\n",
    "        axes[1, i].imshow(decoded.cpu().detach().numpy()[0], cmap='gray')\n",
    "        axes[1, i].set_title(f\"Train reconstructed {classes[train_set[index][1]]}\")\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    for i in range(num_cols // 2, num_cols):\n",
    "        # Test images\n",
    "        index = random.randint(0, validation_set.__len__())\n",
    "\n",
    "        axes[0, i].imshow(validation_set.get_image_2d(index), cmap='gray')\n",
    "        axes[0, i].set_title(f\"Validation original, {validation_set[index][1]}\")\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "        # Reconstructed images\n",
    "        validation_tensor = torch.from_numpy(validation_set[index][0]).to(device)\n",
    "        encoded, decoded = autoencoder_model(validation_tensor)\n",
    "        decoded = decoded.view(-1, HEIGHT, WIDTH)\n",
    "\n",
    "        axes[1, i].imshow(decoded.cpu().detach().numpy()[0], cmap='gray')\n",
    "        axes[1, i].set_title(f\"Validation reconstructed {classes[validation_set[index][1]]}\")\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Call the function\n",
    "show_images(training_set, validation_set, autoencoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Show image with the lowest psnr then ssim in the test set\n",
    "def return_lowest_image_index_psnr_ssim(dataset, autoencoder_model):\n",
    "    lowest_psnr = 100\n",
    "    lowest_ssim = 100\n",
    "    lowest_psnr_index = 0\n",
    "    lowest_ssim_index = 0\n",
    "\n",
    "    for batch in dataset:\n",
    "        test_images, test_labels = batch\n",
    "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "\n",
    "        _, decoded = autoencoder_model(test_images)\n",
    "\n",
    "        decoded_matrices = decoded.cpu().detach().numpy()\n",
    "        test_images_matrices = test_images.cpu().detach().numpy()\n",
    "\n",
    "        for i in range(test_images.size(0)):\n",
    "            image_matrix = test_images_matrices[i]\n",
    "            decoded_matrix = decoded_matrices[i]\n",
    "\n",
    "            psnr_value = psnr(image_matrix, decoded_matrix)\n",
    "            ssim_value = ssim(image_matrix, decoded_matrix, data_range=decoded_matrix.max() - decoded_matrix.min())\n",
    "            \n",
    "            if psnr_value < lowest_psnr:\n",
    "                lowest_psnr = psnr_value\n",
    "                lowest_psnr_index = i\n",
    "\n",
    "            if ssim_value < lowest_ssim:\n",
    "                lowest_ssim = ssim_value\n",
    "                lowest_ssim_index = i\n",
    "\n",
    "    return [lowest_psnr_index, lowest_psnr], [lowest_ssim_index, lowest_ssim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "CHECK_BACTH_SIZE = 8000\n",
    "\n",
    "training_check_dataloader= DataLoader(training_set, batch_size=CHECK_BACTH_SIZE, shuffle=False)\n",
    "validation_check_dataloader = DataLoader(validation_set, batch_size=CHECK_BACTH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lowest_psnr, lowest_ssim = return_lowest_image_index_psnr_ssim(validation_check_dataloader, autoencoder_model)\n",
    "print(f'Lowest PSNR index: {lowest_psnr[0]}|{lowest_psnr[1]}, Lowest SSIM index: {lowest_ssim[0]}|{lowest_ssim[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Show image with the lowest psnr and ssim compared to their original the test set on same plot\n",
    "def show_lowest_psnr_ssim_image(image_set, autoencoder_model, lowest_psnr, lowest_ssim):\n",
    "    lowest_psnr_index, psnr  = lowest_psnr\n",
    "    psnr_image_label = classes[image_set[lowest_psnr_index][1]]\n",
    "\n",
    "    lowest_ssim_index, ssim  = lowest_ssim\n",
    "    ssim_image_label = classes[image_set[lowest_ssim_index][1]]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(7, 6))\n",
    "\n",
    "    # PSNR image\n",
    "    axes[0, 0].imshow(image_set.get_image_2d(lowest_psnr_index), cmap='gray')\n",
    "    axes[0, 0].set_title(\"Original : \" + psnr_image_label)\n",
    "    axes[0, 0].axis('off')\n",
    "\n",
    "    psnr_image_tensor = torch.from_numpy(image_set[lowest_psnr_index][0]).to(device)\n",
    "    _, decoded = autoencoder_model(psnr_image_tensor)\n",
    "    decoded = decoded.view(-1, HEIGHT, WIDTH)  # Reshape decoded images\n",
    "\n",
    "    axes[0, 1].imshow(decoded.cpu().detach().numpy()[0], cmap='gray')\n",
    "    axes[0, 1].set_title(f\"Reconstructed : {psnr_image_label}, PSNR: {psnr:.4f}\")\n",
    "    axes[0, 1].axis('off')\n",
    "\n",
    "    # SSIM image\n",
    "    axes[1, 0].imshow(image_set.get_image_2d(lowest_ssim_index), cmap='gray')\n",
    "    axes[1, 0].set_title(\"Original : \" + ssim_image_label)\n",
    "    axes[1, 0].axis('off')\n",
    "\n",
    "    ssim_image_tensor = torch.from_numpy(image_set[lowest_ssim_index][0]).to(device)\n",
    "    _, decoded = autoencoder_model(ssim_image_tensor)\n",
    "    decoded = decoded.view(-1, HEIGHT, WIDTH)  # Reshape decoded images\n",
    "\n",
    "    axes[1, 1].imshow(decoded.cpu().detach().numpy()[0], cmap='gray')\n",
    "    axes[1, 1].set_title(f\"Reconstructed : {ssim_image_label}, SSIM: {ssim:.4f}\")\n",
    "    axes[1, 1].axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Call the function\n",
    "show_lowest_psnr_ssim_image(validation_set, autoencoder_model, lowest_psnr, lowest_ssim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Try with a different model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "layers = [WIDTH * HEIGHT, WIDTH * HEIGHT]\n",
    "autocoder_2 = Autoencoder(layers).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autocoder_2.parameters(), lr=0.001)\n",
    "\n",
    "# Print architecture\n",
    "autocoder_2.print_model()\n",
    "\n",
    "# Compression factor\n",
    "print(f'Compression factor: {WIDTH * HEIGHT / autocoder_2.architecture[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Call the function\n",
    "num_epochs = 40\n",
    "\n",
    "train_loss_values, validation_loss_values, train_psnr_values, train_ssim_values, validation_psnr_values, validation_ssim_values \\\n",
    "    = train_autoencoder(autocoder_2, training_loaded_set, validation_loaded_set, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plot_psnr_ssim(train_loss_values, validation_loss_values, train_psnr_values, validation_psnr_values, train_ssim_values, validation_ssim_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_images(training_set, validation_set, autocoder_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lowest_psnr, lowest_ssim = return_lowest_image_index_psnr_ssim(validation_check_dataloader, autocoder_2)\n",
    "print(f'Lowest PSNR index: {lowest_psnr[0]}|{lowest_psnr[1]}, Lowest SSIM index: {lowest_ssim[0]}|{lowest_ssim[1]}')\n",
    "\n",
    "show_lowest_psnr_ssim_image(validation_set, autocoder_2, lowest_psnr, lowest_ssim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Try with resnet18 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Use pretrained model\n",
    "\n",
    "# Load pretrained model\n",
    "\n",
    "pretrained_model = models.resnet18(pretrained=True)\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "# Print pretrained model architecture\n",
    "print(pretrained_model)\n",
    "\n",
    "# Freeze all layers\n",
    "\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Add custom layers\n",
    "\n",
    "pretrained_model.fc = nn.Sequential(\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, nb_classes)\n",
    ")\n",
    "\n",
    "# Print new model architecture\n",
    "print(pretrained_model)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(pretrained_model.fc.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to train the model\n",
    "def train_pretained_model():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Generating images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def return_classes_mean_encoded_vector(model, images_set):\n",
    "    mean_encoded_vectors = []\n",
    "    mean_vectors_size = model.architecture[-1]\n",
    "    count_classes_number = [0] * nb_classes\n",
    "\n",
    "    for i in range(nb_classes):\n",
    "        mean_encoded_vectors.append(np.zeros(mean_vectors_size))\n",
    "\n",
    "    for batch in images_set:\n",
    "        images, labels = batch\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        encoded, decoded = model(images)\n",
    "        encoded_np = encoded.cpu().detach().numpy()\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            mean_encoded_vectors[labels[i]] += encoded_np[i]\n",
    "\n",
    "        count_classes_number[labels[i]] += 1\n",
    "            \n",
    "    for i in range(nb_classes):\n",
    "        mean_encoded_vectors[i] = mean_encoded_vectors[i] / count_classes_number[i] / 255.0\n",
    "\n",
    "        print(f'Class {classes[i]} range of mean encoded vector: [{mean_encoded_vectors[i].min()}, {mean_encoded_vectors[i].max()}]')\n",
    "\n",
    "    return mean_encoded_vectors\n",
    "\n",
    "def generated_images_for_mean_vector(mean_encoded_vectors, model):\n",
    "    generated_images = []\n",
    "\n",
    "    decoder = model.decoder\n",
    "    for i in range(nb_classes):\n",
    "        mean_vector = mean_encoded_vectors[i]\n",
    "        double_mean_vector = np.array([mean_vector]).astype(np.float32)\n",
    "        mean_vector_torch = torch.from_numpy(double_mean_vector).to(device)\n",
    "\n",
    "        decoded = decoder(mean_vector_torch)\n",
    "\n",
    "        generated_images.append(decoded.cpu().detach().numpy()[0].reshape(HEIGHT, WIDTH))\n",
    "\n",
    "    return generated_images\n",
    "\n",
    "def show_generated_images(generated_images):\n",
    "    num_cols = 4\n",
    "    num_rows = 2\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 6))\n",
    "\n",
    "    for i in range(nb_classes):\n",
    "        row_index = i // num_cols\n",
    "        col_index = i % num_cols\n",
    "        axes[row_index, col_index].imshow(generated_images[i], cmap='gray')\n",
    "        axes[row_index, col_index].axis('off')\n",
    "        axes[row_index, col_index].set_title(classes[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Generated images')\n",
    "\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def create_alternative_version(mean_vector, weight=0.1):\n",
    "    alternative_mean_vector = mean_vector.copy()\n",
    "    # Vector is composed of float values \n",
    "    # use gaussian distribution to generate altertivate vector based on mean one\n",
    "\n",
    "    for i in range(len(mean_vector)):\n",
    "        alternative_mean_vector[i] = np.random.normal(mean_vector[i], weight)\n",
    "    \n",
    "    return alternative_mean_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mean_encoded_vectors = return_classes_mean_encoded_vector(autoencoder_model, training_loaded_set)\n",
    "generated_images = generated_images_for_mean_vector(mean_encoded_vectors, autoencoder_model)\n",
    "show_generated_images(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "alternative_versions = []\n",
    "for mean_encoded_vector in mean_encoded_vectors:\n",
    "    alternative_versions.append(create_alternative_version(mean_encoded_vector, 0.05))\n",
    "\n",
    "alternative_generated_version = generated_images_for_mean_vector(alternative_versions, autoencoder_model)\n",
    "show_generated_images(alternative_generated_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mean_encoded_vectors = return_classes_mean_encoded_vector(autoencoder_model, training_loaded_set)\n",
    "generated_images = generated_images_for_mean_vector(mean_encoded_vectors, autoencoder_model)\n",
    "show_generated_images(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "alternative_versions = []\n",
    "for mean_encoded_vector in mean_encoded_vectors:\n",
    "    alternative_versions.append(create_alternative_version(mean_encoded_vector, 0.05))\n",
    "\n",
    "alternative_generated_version = generated_images_for_mean_vector(alternative_versions, autoencoder_model)\n",
    "show_generated_images(alternative_generated_version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
